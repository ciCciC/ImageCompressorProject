{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VQVAE and Residual Stack"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-15T14:35:39.143151Z",
     "start_time": "2023-07-15T14:35:36.413303Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import layers as Layer, Input, Model, Sequential\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Mean, MAE\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T14:35:41.711431Z",
     "start_time": "2023-07-15T14:35:41.700063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "class ResidualStack(tf.Module):\n",
    "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "                 name=None):\n",
    "        super(ResidualStack, self).__init__(name=name)\n",
    "        self._num_hiddens = num_hiddens\n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        self._num_residual_hiddens = num_residual_hiddens\n",
    "\n",
    "        self._layers = []\n",
    "        for idx in range(num_residual_layers):\n",
    "            conv3 = Layer.Conv2D(num_residual_hiddens, kernel_size=3, strides=1, padding='same', name=f'res3x3_{idx}')\n",
    "            conv1 = Layer.Conv2D(num_hiddens, kernel_size=1, strides=1, padding='same', name=f'res1x1_{idx}')\n",
    "            self._layers.append((conv3, conv1))\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        h = inputs\n",
    "        for conv3, conv1 in self._layers:\n",
    "            conv3_out_l = conv3(tf.nn.relu(h))\n",
    "            conv1_out_l = conv1(tf.nn.relu(conv3_out_l))\n",
    "            h += conv1_out_l\n",
    "        return tf.nn.relu(h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:43:03.881775Z",
     "start_time": "2023-07-15T18:43:03.868512Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "                 name=None):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "\n",
    "        self._num_hiddens = num_hiddens\n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        self._num_residual_hiddens = num_residual_hiddens\n",
    "\n",
    "        self._enc_l1 = Layer.Conv2D(self._num_hiddens // 2, kernel_size=(4, 4), strides=(2, 2), padding='same', name='enc_l1')\n",
    "        self._enc_l2 = Layer.Conv2D(self._num_hiddens, kernel_size=(4, 4), strides=(2, 2), padding='same', name='enc_l2')\n",
    "        self._enc_l3 = Layer.Conv2D(self._num_hiddens, kernel_size=(3, 3), strides=(1, 1), padding='same', name='enc_l3')\n",
    "        self._residual_stack = ResidualStack(self._num_hiddens, self._num_residual_layers, self._num_residual_hiddens,\n",
    "                                             name='resblock1')\n",
    "\n",
    "    def call(self, input, training=None, mask=None):\n",
    "        h = tf.nn.relu(self._enc_l1(input))\n",
    "        h = tf.nn.relu(self._enc_l2(h))\n",
    "        h = tf.nn.relu(self._enc_l3(h))\n",
    "        return self._residual_stack(h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:43:04.603322Z",
     "start_time": "2023-07-15T18:43:04.587391Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "                 name=None):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "\n",
    "        self._num_hiddens = num_hiddens\n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        self._num_residual_hiddens = num_residual_hiddens\n",
    "\n",
    "        self._dec1 = Layer.Conv2D(self._num_hiddens, kernel_size=(3, 3), strides=(1, 1), padding='same', name='dec_l1')\n",
    "\n",
    "        self._residual_stack = ResidualStack(\n",
    "            self._num_hiddens,\n",
    "            self._num_residual_layers,\n",
    "            self._num_residual_hiddens,\n",
    "            name='resblock2'\n",
    "        )\n",
    "\n",
    "        self._dec2 = Layer.Conv2DTranspose(self._num_hiddens // 2, kernel_size=(4, 4), strides=(2, 2), padding='same', name='dec_l2')\n",
    "        self._dec3 = Layer.Conv2DTranspose(3, kernel_size=(4, 4), strides=(2, 2), padding='same', name='dec_l3')\n",
    "        # self._up1 = Layer.UpSampling2D()\n",
    "        # self._up2 = Layer.UpSampling2D()\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        h = self._dec1(inputs)\n",
    "        h = self._residual_stack(h)\n",
    "        h = tf.nn.relu(self._dec2(h))\n",
    "        # h = self._up1(h)\n",
    "        # h = self._dec3(h)\n",
    "        reconstruction = self._dec3(h)\n",
    "        return reconstruction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:43:05.807974Z",
     "start_time": "2023-07-15T18:43:05.797419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "class VectorQuantizer(Layer.Layer):\n",
    "    # beta -> commitment cost\n",
    "    def __init__(self, embedding_dim, num_embeddings, beta=0.25, name=None):\n",
    "        super(VectorQuantizer, self).__init__(name=name)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.beta = beta\n",
    "\n",
    "        # Initialize the embeddings to quantize by pre-specifying random uniform distribution\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact\n",
    "        input_shape = tf.shape(inputs)\n",
    "        flattened = tf.reshape(inputs, [-1, self.embedding_dim])\n",
    "\n",
    "        # Quantization\n",
    "        encoding_indices = self.get_code_indices(flattened)\n",
    "        # Apply one hot\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
    "        # Compute Matrix Multiplication\n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "\n",
    "        # Reshape the quantized values back to the original input shape\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        # Calculate the vector quantization loss\n",
    "        commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - inputs) ** 2)\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(inputs)) ** 2)\n",
    "        #  Add the calculation to the layer\n",
    "        self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator\n",
    "        quantized = inputs + tf.stop_gradient(quantized - inputs)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate the L2-normalized distance between the inputs and the codes\n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        # Obtain distance distribution\n",
    "        distances = (\n",
    "                tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
    "                + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
    "                - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'num_embeddings': self.num_embeddings,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'beta': self.beta\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:43:06.674889Z",
     "start_time": "2023-07-15T18:43:06.665201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def get_vqvae(shape, latent_dim, num_embeddings, model_encoder, model_decoder):\n",
    "    vq_layer = VectorQuantizer(latent_dim, num_embeddings, name=\"vector_quantizer\")\n",
    "    pre_vq_inputs = Layer.Conv2D(latent_dim, kernel_size=(1,1), strides=(1,1), name='to_vq')\n",
    "    inputs = Input(shape=shape)\n",
    "    encoder_outputs = model_encoder(inputs)\n",
    "    z = pre_vq_inputs(encoder_outputs)\n",
    "    quantized_latents = vq_layer(z)\n",
    "    reconstructions = model_decoder(quantized_latents)\n",
    "    return Model(inputs, reconstructions, name=\"vq_vae\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:43:08.302906Z",
     "start_time": "2023-07-15T18:43:08.299531Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class VQVAETrainer(Model):\n",
    "    def __init__(self, input_shape, num_hiddens, num_residual_layers, num_residual_hiddens, train_variance, latent_dim,\n",
    "                 num_embeddings, name=None):\n",
    "        super(VQVAETrainer, self).__init__(name=name)\n",
    "        self.train_variance = train_variance\n",
    "        self.latent_dim = latent_dim #embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.model_encoder = Encoder(num_hiddens=self.num_hiddens, num_residual_layers=num_residual_layers,\n",
    "                                     num_residual_hiddens=num_residual_hiddens, name='Encoder')\n",
    "        self.model_decoder = Decoder(num_hiddens=self.num_hiddens, num_residual_layers=num_residual_layers,\n",
    "                                     num_residual_hiddens=num_residual_hiddens, name='Decoder')\n",
    "\n",
    "        self.vqvae = get_vqvae(\n",
    "            shape=input_shape,\n",
    "            latent_dim=self.latent_dim,\n",
    "            num_embeddings=self.num_embeddings,\n",
    "            model_encoder=self.model_encoder,\n",
    "            model_decoder=self.model_decoder)\n",
    "\n",
    "        self.total_loss_tracker = Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.vq_loss_tracker = Mean(name=\"vq_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.vq_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Outputs from the VQ-VAE.\n",
    "            reconstructions = self.vqvae(x)\n",
    "\n",
    "            # Calculate the losses.\n",
    "            reconstruction_loss = (tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance)\n",
    "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
    "\n",
    "        # Backpropagation\n",
    "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
    "\n",
    "        # Loss tracking\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
    "\n",
    "        # Log results.\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:43:09.047794Z",
     "start_time": "2023-07-15T18:43:09.037371Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "\n",
    "# x_train = np.expand_dims(x_train, -1)\n",
    "# x_test = np.expand_dims(x_test, -1)\n",
    "x_train_scaled = (x_train / 255.0) - 0.5\n",
    "x_test_scaled = (x_test / 255.0) - 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:46:05.841558Z",
     "start_time": "2023-07-15T18:46:04.851868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 32, 32, 3)"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:46:07.372707Z",
     "start_time": "2023-07-15T18:46:07.360154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:-1]\n",
    "num_hiddens = 128\n",
    "num_residual_layers = 2\n",
    "num_residual_hiddens = 32\n",
    "data_variance = np.var(x_train / 255.0)\n",
    "embedding_dim = 64\n",
    "num_embeddings = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:46:13.608310Z",
     "start_time": "2023-07-15T18:46:12.079744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "(32, 32, 3)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:46:29.563726Z",
     "start_time": "2023-07-15T18:46:29.551936Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize a VQVAETrainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "vqvae_trainer = VQVAETrainer(\n",
    "    input_shape=x_train.shape[1:],\n",
    "    num_hiddens=num_hiddens,\n",
    "    num_residual_layers=num_residual_layers,\n",
    "    num_residual_hiddens=num_residual_hiddens,\n",
    "    train_variance=data_variance,\n",
    "    latent_dim=embedding_dim,\n",
    "    num_embeddings=num_embeddings,\n",
    "    name='VQVAETrainer'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:46:33.382613Z",
     "start_time": "2023-07-15T18:46:33.252509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vq_vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " Encoder (Encoder)           (None, 8, 8, 128)         364160    \n",
      "                                                                 \n",
      " to_vq (Conv2D)              (None, 8, 8, 64)          8256      \n",
      "                                                                 \n",
      " vector_quantizer (VectorQua  (None, 8, 8, 64)         32768     \n",
      " ntizer)                                                         \n",
      "                                                                 \n",
      " Decoder (Decoder)           (None, 32, 32, 3)         290307    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 695,491\n",
      "Trainable params: 695,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vqvae_trainer.vqvae.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:46:34.478209Z",
     "start_time": "2023-07-15T18:46:34.464623Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vqvae_trainer.compile(optimizer=Adam())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 20:46:37.303328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 35ms/step - loss: 121.8134 - reconstruction_loss: 0.3686 - vqvae_loss: 121.3069\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 1.4192 - reconstruction_loss: 0.2266 - vqvae_loss: 1.1760\n"
     ]
    }
   ],
   "source": [
    "history = vqvae_trainer.fit(x_train_scaled,\n",
    "                            epochs=2,\n",
    "                            batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:47:05.397317Z",
     "start_time": "2023-07-15T18:46:35.907427Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot performance of the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
